{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Say that I run exactly a mile every single day and record the time. Unfortunately I\"m not getting exactly better at it over time, though there is noise in my performance. In fact, my mile time follows a normal distribution with a mean of seven minutes (for ease we'll say 420 seconds) and a standard deviation of fifteen seconds.\n",
    "\n",
    "Unfortunately my phone gets hacked, and there's a chance that someone has gone in and modified my historical run times. How will I know which times are mine, and which may be compromised?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) Create a PDF graph of this distribution with the proper labels on the axes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Say we wanted to create a rejection region for any mile times that look suspicious. If we set the rejection region with a p-value of 0.05 in a two-sided test, what values would constitute the cutoffs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Say now that I'm only concerned about looking too slow, meaning I'm only concerned about outliers at the lower end. If we set the rejection region with a p-value of 0.05, what value would constitute the cutoff?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) If I see a run-time of 396 seconds, what p-value would this value get in a one-sided test? Can we reject the null hypothesis at a significance level of 0.05? What p-value would it get in a two-sided test? Can we reject the null hypothesis at a significance level of 0.05?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Now I want to look at the mean of twenty random samples from this distribution to see if this is different than what I would expect. What would the mean and standard deviation of this new distribution (of the mean of twenty samples taken from the underlying distribution) be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) Again, I'm only concerned about looking too slow. What is the rejection region of the mean of twenty random samples taken from the distribution at a signifiance level of 0.01?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7) Say that I'm unsure of my original standard deviation estimation, especially because the data may have been tampered. I want to use my twenty random samples below to estimate the standard deviation of the underlying distribution. First, what would the mean and standard deviation of this new distribution (of the mean of twenty samples taken from the underlying distribution given our new standard deviation) be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "values =  [417.95,\n",
    "           380.87,\n",
    "           424.89,\n",
    "           404.97,\n",
    "           381.5,\n",
    "           416.86,\n",
    "           409.4,\n",
    "           429.15,\n",
    "           436.96,\n",
    "           437.95,\n",
    "           392.05,\n",
    "           426.85,\n",
    "           415.48,\n",
    "           428.43,\n",
    "           424.53,\n",
    "           415.31,\n",
    "           415.37,\n",
    "           422.77,\n",
    "           425.23]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8) Again, I'm only concerned about looking too slow. What is the rejection region of the mean of twenty random samples taken from the distribution at a signifiance level of 0.01?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9) What is the p-value of the mean of our samples (one-sided test)? Can we reject the null hypothesis that these samples could been taken from the original distribution?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BONUS: 10) Say that the probability of me coming to class on time is 30%. If I come into class fifteen times in the semester, you could say that the distribution of me coming into class on time throughout the semester fits a binomial distribution with a probability of 0.3 and fifteen independent trials.\n",
    "\n",
    "Using the normal approxmation, say you wanted to calculate the probability that I've been replaced with a body double throughout the semester. At a signifiance level of 0.05 in a two-sided test, what would the **discrete** rejection regions be that it wasn't actually me coming to class anymore? Or, to put it another way, how little and many times would I have to come to class on time for it to be actually suspicious? Be sure to keep the **continuity correction** in mind and use the underlying binomial distribution for proof if you need to."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
